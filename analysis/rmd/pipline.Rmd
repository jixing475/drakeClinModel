---
title: "Untitled"
author: "Jixing Liu"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  html_notebook:
    theme: united
    highlight: zenburn
    toc: true
    toc_float:
      toc_collapsed: true
    toc_depth: 3
    number_sections: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,      # Output code chunks
    message = TRUE,  # Toggle off message output 
    warning = TRUE,    # Toggle off warning output
    fig.width = 6, fig.asp = 0.618, out.width = "70%", fig.align = "center") 

knitr::opts_knit$set(root.dir = usethis::proj_path())
#library(docknitr)

# libraries used in report
library(knitr)
library(kableExtra)
library(tidyverse)

# Globql formatting options
options(digits = 3)

# Global table settings 
options(DT.options = list(pageLength = 10, 
                          language = list(search = 'Filter:'), 
                          scrollX = TRUE))
# Global ggplot settings
theme_set(theme_light(base_family = "Avenir"))
```


## conda åˆ›å»º python è¿è¡Œç¯å¢ƒ
```{bash eval=FALSE, include=TRUE}
conda create -n clinModel -y python==3.7
conda activate clinModel

conda install pandas matplotlib numpy scikit-learn xgboost  seaborn
conda install xlrd

#pip3 install graphviz
conda install graphviz
```


## è®¾ç½® reticulate python 
```{r set python}
library(reticulate)
reticulate::use_python("/Users/zero/anaconda3/envs/clinModel/bin/python", required = TRUE)
reticulate::py_config()
# knitr::knit_engines$set(python = reticulate::eng_python) è¿™ä¸ªè®¾ç½®åè€Œä¼šé€ æˆ chunk ä¹‹é—´çš„ R å’Œ python çš„å˜é‡æ²¡èƒ½äº’é€š
```

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj4x2lg6lgj31cq0ioadz.jpg)

## ğŸ æ¨¡å—è°ƒç”¨

```{python}
# -- coding:utf-8 --
import pandas as pd
import numpy as np
import os
from os.path import join as pjoin

# from utils import is_number

import matplotlib.pyplot as plt
import seaborn as sns
import warnings

import xgboost as xgb
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from matplotlib import pyplot as plt
from matplotlib.colors import ListedColormap

from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn import preprocessing

from mpl_toolkits.mplot3d import Axes3D
# import utils
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve, auc
import matplotlib as mpl

warnings.filterwarnings('ignore')
#%matplotlib inline
sns.set_style("white")

plt.rcParams['font.sans-serif']=['Simhei']
plt.rcParams['axes.unicode_minus']=False

```

```{python}
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn import metrics
from sklearn.metrics import f1_score
from sklearn.metrics import matthews_corrcoef
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score 

from sklearn.naive_bayes import BernoulliNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
```

## ğŸ å˜é‡è®¾ç½®

```{python}
RANDOM_STATE = 123
CV = 5
```

## ğŸ è‡ªå®šä¹‰å‡½æ•°

### StratifiedKFold_func_with_features_sel

è¿™ä¸ªå‡½æ•°çš„ä½œç”¨ä¸»è¦æ˜¯ç”¨ KæŠ˜çš„åŠæ³•ç®—ä¸€äº›æŒ‡æ ‡  

è¾“å…¥: X, y(ç‰¹å¾å’Œç›®æ ‡)  

è¾“å‡º: æŒ‡æ ‡çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®

```{python}
def StratifiedKFold_func_with_features_sel(x, y,Num_iter=100,score_type = 'auc'):
    # åˆ†å±‚ K æŠ˜äº¤å‰éªŒè¯
    acc_v = []
    acc_t = []
    # æ¯æ¬¡KæŠ˜100æ¬¡ï¼
    for i in range(Num_iter):
        # æ¯æ¬¡æŠ˜æ˜¯éšæœºçš„random_state=i
        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)
        for tr_idx, te_idx in skf.split(x,y):
            x_tr = x[tr_idx, :]
            y_tr = y[tr_idx]
            x_te = x[te_idx, :]
            y_te = y[te_idx]
            #å®šä¹‰æ¨¡å‹è¶…å‚æ•°
            model = xgb.XGBClassifier(max_depth=4,learning_rate=0.2,reg_alpha=1)
            #æ¨¡å‹æ‹Ÿåˆ
            model.fit(x_tr, y_tr)
            pred = model.predict(x_te)
            train_pred = model.predict(x_tr)
            #è°ƒç”¨sklearn çš„roc_auc_score ä¸f1_scoreè®¡ç®—ç›¸å…³æŒ‡æ ‡
            # 1. accuracy_score
            # 2. recall_score
            # 3. f1_score
            # 4. roc_auc_score
            ## æ³¨æ˜Læ­¤å¤„ç”¨é¢„æµ‹çš„æ ‡ç­¾å€¼è€Œä¸æ˜¯é¢„æµ‹æ¦‚ç‡æ±‚çš„AUC,åŸå› æ˜¯å› ä¸ºæœ¬æ–‡ç€é‡è€ƒè™‘é¢„æµ‹åŒºåˆ†ç”Ÿæ­»ï¼Œè¿ç”¨é¢„æµ‹æ ‡ç­¾ç›¸å½“äºåœ¨é˜ˆå€¼ç¡®å®šä¸º0.5çš„æƒ…å†µä¸‹æ¨¡å‹çš„ç»“æœéªŒè¯ï¼Œ
            ## å…¶AUCé˜ˆå€¼åˆ†å‰²ç‚¹å¯è§†ä¸ºåˆ†åˆ«åœ¨1ï¼Œ0.5ï¼Œ0, è¿™æ ·æ›´èƒ½ååº”ç‰¹å¾çš„åŒºåˆ†æ€§èƒ½çš„å·®å¼‚æ€§ï¼Œæ‰¾å‡ºèƒ½æœ‰åŒºåˆ†åº¦è´¡çŒ®çš„ç‰¹å¾ã€‚
            if score_type == 'auc':
                acc_v.append(roc_auc_score(y_te, pred))
                acc_t.append(roc_auc_score(y_tr, train_pred))
            else:
                acc_v.append(f1_score(y_te, pred))
                acc_t.append(f1_score(y_tr, train_pred))    
    # è¿”å›å¹³å‡å€¼
    return [np.mean(acc_t), np.mean(acc_v), np.std(acc_t), np.std(acc_v)]
```

### show_confusion_matrix
```{python}
## Plot functions
######################
def show_confusion_matrix(validations, predictions):
    LABELS = ['Survival','Death']
    matrix = metrics.confusion_matrix(validations, predictions)
    # plt.figure(dpi=400,figsize=(4.5, 3))
    plt.figure(figsize=(4.5, 3))
    sns.heatmap(matrix,
                cmap='coolwarm',
                linecolor='white',
                linewidths=1,
                xticklabels=LABELS,
                yticklabels=LABELS,
                annot=True,
                fmt='d')
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

```



## æ•°æ®æ•´ç†

å¯ä»¥æ˜¯ä¸€ä¸ªè„šæœ¬, æœ€å¥½æ˜¯ç»“åˆ drake ä¸€èµ·ä½¿ç”¨


## æ•°æ®åŠ è½½: X , y

è¿™é‡Œé¢çš„æ•° X, y æ˜¯æ•°æ®æ¡†

```{r}
train <- rio::import("analysis/data/raw_data/jixing/train_357.csv")
validation <- rio::import("analysis/data/raw_data/jixing/validation_110.csv")

train_X <- select(train, -"label") 
train_Y  <- select(train, "label") 

```



## MRMR: ç‰¹å¾é‡è¦æ€§æ’åº

ç‰¹å¾æ’åºçŸ©é˜µ, è·Ÿ MRMRçš„åŠŸèƒ½å·®ä¸å¤š, åœ¨æ•°æ®é‡æ¯”è¾ƒå°çš„æ—¶å€™

å®šä¹‰è®¡ç®—ç‰¹å¾é‡è¦æ€§çš„å‡½æ•°

```{python}
def features_rank(X, y):
  # æ„å»ºä¸€ä¸ªdataframeç”¨äºå­˜å‚¨ç‰¹å¾çš„é‡è¦ç¨‹åº¦ä¿¡æ¯
  import_feature = pd.DataFrame()
  import_feature['col'] = X.columns.tolist()
  import_feature['model'] = 0
  # é‡å¤100æ¬¡è¯•éªŒ
  for i in range(100): # 50,150
      #æ¯æ¬¡è¯•éªŒå°†375æ•°æ®éšæœºåˆ’åˆ†0.7è®­ç»ƒé›†å’Œ0.3æµ‹è¯•é›†ï¼Œæ³¨æ„éšæœºrandom_state=i
      ## æ³¨æ˜ï¼šæ­¤æ–¹æ³•åŸå› æ˜¯ç”±äºå¯è·å¾—çš„æ ·æœ¬é‡è¾ƒå°‘ï¼Œä¸ºäº†äº§ç”Ÿä¸åŒçš„è®­ç»ƒæ ·æœ¬é›†ï¼Œä½¿å¾—ç‰¹å¾çš„é‡è¦åº¦æ’åºæ›´ä¸ºç¨³å®šï¼Œä»è€Œé€‰æ‹©äº†è¿™æ ·ä¸€ç§æ–¹å¼ã€‚
      ## é€šè¿‡æ¯æ¬¡ä¸åŒçš„éšæœºç§å­äº§ç”Ÿä¸åŒçš„æ ·æœ¬ï¼Œä»è€Œè¾¾åˆ°ä¸€å®šç¨‹åº¦ä¸Šçš„æŠ‘åˆ¶å°‘é‡æ ·æœ¬çš„å¼‚å¸¸å¯¹ç‰¹å¾çš„é‡è¦åº¦å¸¦æ¥çš„å½±å“ã€‚
      x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)
      #å®šä¹‰æ¨¡å‹è¶…å‚æ•°
      model = xgb.XGBClassifier(
              max_depth=4
              ,learning_rate=0.2
              ,reg_lambda=1
              ,n_estimators=150
              ,subsample = 0.9
              ,colsample_bytree = 0.9)
      #æ¨¡å‹æ‹Ÿåˆ
      model.fit(x_train, y_train)
      #ç´¯åŠ ç‰¹å¾é‡è¦ç¨‹åº¦
      import_feature['model'] = import_feature['model'] + model.feature_importances_/100
  # æŒ‰ç…§ç‰¹å¾é‡è¦ç¨‹åº¦ï¼Œé™åºæ’åˆ—
  return import_feature
```

ç‰¹å¾é‡è¦æ€§æ’åºæ•°æ®è¡¨è®¡ç®—

```{python}
feature_rank_res = features_rank(r.train_X, r.train_Y)
```

```{r}
py$feature_rank_res %>% view()
```

å‰ 10 æœ€é‡è¦çš„ç‰¹å¾
```{r}
# è·å–å‰10é‡è¦ç‰¹å¾çš„é‡è¦æ€§æ•°å€¼
(import_feature_cols <- 
  py$feature_rank_res %>% 
  arrange(desc(model)) %>% 
  head(10) %>% 
  pull(col)
 )
```

## IFS: ç¡®å®šé‡è¦ç‰¹å¾å­é›†

è‡ªå®šä¹‰ IFS å‡½æ•°:

1. è¿™é‡Œä¸æ˜¯ LOOCV è€Œæ˜¯ äº”æŠ˜
2. æ¯ä¸ªå­ç‰¹å¾é›†, éƒ½æ˜¯é‡å¤100 æ¬¡äº”æŠ˜äº¤å‰
3. è¿™é‡Œé¢çš„è¡¡é‡æŒ‡æ ‡å¯ä»¥æ”¹å˜


```{python}
def IFS_K_fold(import_feature_cols, X, y):
  # å®šä¹‰å››ä¸ªæŒ‡æ ‡æ”¶é›†å™¨, åç»­åˆå¹¶æˆ dataframe
  acc_train = [None] * 10
  acc_val = [None] * 10
  acc_train_std = [None] * 10
  acc_val_std = [None] * 10
  # äº”æŠ˜ç‰ˆçš„ IFS
  for num_i in range(0, len(import_feature_cols)):
    print(num_i)
    # æŒ‰é‡è¦ç¨‹åº¦é¡ºåºå–ç‰¹ç§
    x_col = import_feature_cols[:num_i + 1]
    print(x_col)
    X_select = X[x_col]#.values
    ## äº¤å‰éªŒè¯
    print('5-Fold CV:')
    acc_train[num_i], acc_val[num_i], acc_train_std[num_i], acc_val_std[num_i] = StratifiedKFold_func_with_features_sel(X_select.values, y.values)
    
  res = pd.DataFrame(
      {'acc_train': acc_train,
       'acc_val': acc_val,
       'acc_train_std': acc_train_std,
       'acc_val_std': acc_val_std
      })
  return res

```

```{python}
# ç”»ç‰¹å¾é‡‘å­—å¡”
import_feature_cols = r.import_feature_cols

IFS_res = IFS_K_fold(import_feature_cols, r.train_X, r.train_y)

```

```{r}
py$IFS_res %>% view()
```




## å†³ç­–æ ‘æ¨¡å‹

é€‰å–å‰ 3 é‡è¦çš„ç‰¹å¾

```{r}
cols <- c('ä¹³é…¸è„±æ°¢é…¶', 'æ·‹å·´ç»†èƒ(%)', 'è¶…æ•Cååº”è›‹ç™½')

train_x <- select(train, all_of(cols)) 
train_y  <- select(train, "label") 

validation_x <- select(validation, all_of(cols)) 
validation_y  <- select(validation, "å‡ºé™¢æ–¹å¼") 
```

```{python}

# åœ¨351ç—…äººä¸Šåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œæ­¤æ—¶110è§†ä¸ºæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(r.train_x, r.train_y, test_size=0.3, random_state=6)
#é™å®šå•æ ‘xgbæ¨¡å‹
model = xgb.XGBClassifier(
    max_depth=3,
    n_estimators=1,
)
model.fit(X_train,y_train)

#è®­ç»ƒé›†æ··æ·†çŸ©é˜µ
pred_train = model.predict(X_train)
show_confusion_matrix(y_train, pred_train)
print(classification_report(y_train, pred_train))

#æµ‹è¯•é›†æ··æ·†çŸ©é˜µ
pred_test = model.predict(X_test)
show_confusion_matrix(y_test, pred_test)
print(classification_report(y_test, pred_test))
    
#å¤–éƒ¨é›†æ··æ·†çŸ©é˜µ
pred_test = model.predict(r.validation_x)
print('True test label:',r.validation_y)
print('Predict test label:',pred_test.astype('int32'))
show_confusion_matrix(r.validation_y, pred_test)
print(classification_report(r.validation_y, pred_test))
    
plt.figure(dpi=300,figsize=(8,6))
plot_tree(model)
plt.show()
    
graph = xgb.to_graphviz(model)
graph.render(filename='analysis/data/derived_data/single-tree.dot')
#å•æ ‘å¯è§†åŒ–
def ceate_feature_map(features):
    outfile = open('xgb.fmap', 'w')
    i = 0
    for feat in features:
        outfile.write('{0}\t{1}\tq\n'.format(i, feat))
        i = i + 1
    outfile.close()

ceate_feature_map(r.cols)
graph = xgb.to_graphviz(model, fmap='xgb.fmap', num_trees=0, **{'size': str(10)})
graph.render(filename='single-tree.dot')

```

## æ¨¡å‹ä¹‹é—´çš„æ¯”è¾ƒ

ä¹Ÿå¯ä»¥ç”¨ pycaret æ¥è¯•è¯•

```{python}
features = r.train_x
labels = r.train_y
```


### æ¨¡å‹é€‰æ‹©

```{python}
#------------------------------------------------
# model select training æ²¡æœ‰ DNN
#------------------------------------------------
import sklearn
sorted(sklearn.metrics.SCORERS.keys())

models = [
    RandomForestClassifier(random_state=RANDOM_STATE),
    LinearSVC(random_state=RANDOM_STATE),
    BernoulliNB(),
    LogisticRegression(random_state=RANDOM_STATE),
]

```

### accuracy
```{python}
# accuracy -----------------------------------------------------------
cv_df = pd.DataFrame(index=range(CV * len(models)))
entries = []
for model in models:
  model_name = model.__class__.__name__
  scores = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)
  for fold_idx, score in enumerate(scores):
    entries.append((model_name, fold_idx, score))
cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])

#fig, ax = plt.subplots(figsize=(10,10))
#sns.boxplot(x='model_name', y='accuracy', data=cv_df)
#sns.stripplot(x='model_name', y='accuracy', data=cv_df, 
#              size=8, jitter=True, edgecolor="gray", linewidth=2)
#plt.show()

cv_df.groupby('model_name').accuracy.mean()
accuracy_cv_df = cv_df
```
### MCC

```{python}
# MCC -----------------------------------------------------------
from sklearn.metrics import matthews_corrcoef, make_scorer
MCC = make_scorer(matthews_corrcoef)

cv_df = pd.DataFrame(index=range(CV * len(models)))
entries = []
for model in models:
  model_name = model.__class__.__name__
  scores = cross_val_score(model, features, labels, scoring=MCC, cv=CV)
  for fold_idx, score in enumerate(scores):
    entries.append((model_name, fold_idx, score))
cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'MCC'])

#fig, ax = plt.subplots(figsize=(10,10))
#sns.boxplot(x='model_name', y='MCC', data=cv_df)
#sns.stripplot(x='model_name', y='MCC', data=cv_df, 
#              size=8, jitter=True, edgecolor="gray", linewidth=2)
#plt.show()

cv_df.groupby('model_name').MCC.mean()
MCC_cv_df = cv_df
```

åˆå¹¶ä¹‹åç”¨äºç”»å›¾

```{r}
cv_5_models_metrics <- 
bind_rows(py$accuracy_cv_df, py$MCC_cv_df) %>% 
  pivot_longer(cols = -c("model_name", "fold_idx"),
               names_to = "metrics",
               values_to = "value") %>% 
  filter(!is.na(value)) 
```


```{r}
cv_5_models_metrics %>%
  #filter(metrics == "accuracy") %>%
  ggplot(data = .) +
  aes(x = model_name, y = value, fill = model_name) +
  geom_boxplot(outlier.alpha = 0) +
  geom_dotplot(binaxis='y', stackdir='center',
               position=position_jitterdodge(0.2)) +
  facet_wrap(~ metrics) +
  theme_minimal() + 
  ggthemes::scale_color_tableau() + ggthemes::scale_fill_tableau() 
```


